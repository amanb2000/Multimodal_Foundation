{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceiver Autoencoder\n",
    "\n",
    "In this notebook, I prototype the **full** version of the Perceiver autoencoder. This includes the training loop and any data management that needs to occur with this. Disk-memory-GPU management of data will not be performed, however. \n",
    "\n",
    "**Goals:**\n",
    "Fully adjustable + parameterizable Perceiver for Predictive Coding.\n",
    " - **Encoder**: Adjustable encoder shape, # re-exposures as data is compressed. \n",
    "\t - Let's avoid having a bunch of intermediate {#token, token dim} sizes between the original byte array and the final latent state. \n",
    "\t - The only adjustment should be the # re-exposures -- i.e., the number of different $\\mathbb{R}^{(M \\times D)} \\to \\mathbb{R}^{(N\\times C)}$ encoders there are that re-query the byte array using the current latent estimate. \n",
    " - **Latent-latent**: Number of distinct blocks, number of block repeats between new information exposure. \n",
    " - **Decoder**: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MMF",
   "language": "python",
   "name": "mmf"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7bb424496d90d9eff7a93e13c98d7ddc1d5da3a5925d09c92a85f3c2f93884c9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
